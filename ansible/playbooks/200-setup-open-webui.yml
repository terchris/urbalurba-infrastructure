---
# file: ansible/playbooks/200-setup-open-webui.yml
# Description:
# Set up Open WebUI with all its dependencies on Kubernetes
# - storage: persistent storage for all systems
# - tika: Apache Tika server for document extraction and processing
# - openwebui: the web frontend that connects to LiteLLM proxy for model access
#
# Prerequisites:
# - A PostgreSQL instance must be running in the target namespace with the pgvector extension enabled in the target database (e.g., openwebui)
# - LiteLLM proxy must be deployed and running in the same namespace
# - Persistent storage and required secrets must be set up
#
# Architecture:
# - OpenWebUI connects to LiteLLM proxy for all model interactions
# - LiteLLM provides unified access to Mac Ollama and cloud LLM providers
# - No in-cluster Ollama deployment - all models served via LiteLLM proxy
#
# Usage:
# ansible-playbook playbooks/200-setup-open-webui.yml -e kube_context="rancher-desktop"

- name: Set up Open WebUI with subsystems on Kubernetes
  hosts: localhost
  gather_facts: false
  vars:
    manifests_folder: "/mnt/urbalurbadisk/manifests"
    merged_kubeconf_file: "/mnt/urbalurbadisk/.uis.secrets/generated/kubeconfig/kubeconf-all"
    ai_namespace: "ai"
    installation_timeout: 900  # 15 minutes timeout for installations
    pod_readiness_timeout: 600  # 10 minutes timeout for pod readiness
    # Helm chart references
    tika_chart: "tika/tika"
    openwebui_chart: "open-webui/open-webui"
    openwebui_repo_url: "https://helm.openwebui.com/"
    # Config files
    storage_config_file: "{{ manifests_folder }}/200-ai-persistent-storage.yaml"
    tika_config_file: "{{ manifests_folder }}/201-tika-config.yaml"
    openwebui_config_file: "{{ manifests_folder }}/208-openwebui-config.yaml"
    openwebui_ingress_file: "{{ manifests_folder }}/210-openwebui-ingress.yaml"

  tasks:

    - name: 1. Check existing Helm repositories
      ansible.builtin.command: helm repo list
      register: helm_repo_list
      changed_when: false

    - name: 2. Add Helm repositories if needed
      kubernetes.core.helm_repository:
        name: "{{ item.name }}"
        repo_url: "{{ item.url }}"
      loop:
        - { name: 'tika', url: 'https://apache.jfrog.io/artifactory/tika' }
        - { name: 'open-webui', url: '{{ openwebui_repo_url }}' }
      when: item.name not in helm_repo_list.stdout
      register: helm_repo_result

    - name: 3. Update Helm repositories
      ansible.builtin.command: helm repo update
      changed_when: false

    - name: 4. Apply persistent storage resources
      ansible.builtin.command: kubectl apply -f {{ storage_config_file }} -n {{ ai_namespace }}
      environment:
        KUBECONFIG: "{{ merged_kubeconf_file }}"
      register: storage_result
      changed_when: storage_result.rc == 0
      failed_when: storage_result.rc != 0

    - name: 5. Set up OpenWebUI database on shared PostgreSQL
      ansible.builtin.shell: |
        ansible-playbook utility/u06-openwebui-create-postgres.yml
      args:
        chdir: /mnt/urbalurbadisk/ansible/playbooks
      environment:
        KUBECONFIG: "{{ merged_kubeconf_file }}"
      register: openwebui_db_result
      changed_when: openwebui_db_result.rc == 0
      failed_when: openwebui_db_result.rc != 0

    - name: 5.1. Display utility playbook output on failure
      ansible.builtin.debug:
        msg:
          - "‚ùå OpenWebUI database setup failed!"
          - "Full output from utility playbook:"
          - "{{ openwebui_db_result.stdout_lines }}"
      when: openwebui_db_result.rc != 0

    # 6. Deploy Apache Tika server
    - name: 6. Deploy Apache Tika server
      ansible.builtin.command: >
        helm upgrade --install tika {{ tika_chart }} 
        -f {{ tika_config_file }} 
        --namespace {{ ai_namespace }}
        --timeout {{ installation_timeout }}s
      environment:
        KUBECONFIG: "{{ merged_kubeconf_file }}"
      register: tika_result
      changed_when: true
    
    - name: 7. Display Tika deployment result
      ansible.builtin.debug:
        msg: "Tika deployment initiated. Waiting for readiness..."
    
    - name: 8. Wait for Tika pods to be ready (with progress indicators)
      kubernetes.core.k8s_info:
        kubeconfig: "{{ merged_kubeconf_file }}"
        kind: Pod
        namespace: "{{ ai_namespace }}"
        label_selectors:
          - app.kubernetes.io/name=tika
      register: tika_pods
      retries: 40
      delay: 15
      until: >
        tika_pods.resources | length > 0 and
        tika_pods.resources[0].status.phase == "Running" and
        tika_pods.resources[0].status.conditions | selectattr('type', 'equalto', 'Ready') | map(attribute='status') | first == "True"
      changed_when: false
    
    - name: 9. Display Tika readiness status
      ansible.builtin.debug:
        msg: "Tika readiness status: Ready"
    
    # Install Open WebUI
    - name: 10. Deploy Open WebUI frontend
      ansible.builtin.command: >
        helm upgrade --install open-webui {{ openwebui_chart }}
        -f {{ openwebui_config_file }}
        --namespace {{ ai_namespace }}
        --timeout {{ installation_timeout }}s
      environment:
        KUBECONFIG: "{{ merged_kubeconf_file }}"
      register: openwebui_result
      changed_when: true
    
    - name: 11. Display Open WebUI deployment result
      ansible.builtin.debug:
        msg: "Open WebUI deployment initiated. Waiting for readiness (this may take several minutes)..."
    
    - name: 12. Wait for Open WebUI pods to be ready (with retry for model downloads)
      kubernetes.core.k8s_info:
        kubeconfig: "{{ merged_kubeconf_file }}"
        kind: Pod
        namespace: "{{ ai_namespace }}"
        label_selectors:
          - app.kubernetes.io/name=open-webui
      register: openwebui_pods
      retries: 80
      delay: 15
      until: >
        openwebui_pods.resources | length > 0 and
        openwebui_pods.resources[0].status.phase == "Running" and
        openwebui_pods.resources[0].status.conditions | selectattr('type', 'equalto', 'Ready') | map(attribute='status') | first == "True"

    - name: 13. Display Open WebUI readiness status
      ansible.builtin.debug:
        msg: "Open WebUI readiness status: Ready"

    - name: 13.1. Monitor Open WebUI internal initialization
      ansible.builtin.debug:
        msg: "Waiting for OpenWebUI internal services to initialize (database connections, model loading, etc.)..."

    - name: 13.2. Allow OpenWebUI time to complete internal initialization
      ansible.builtin.pause:
        seconds: 30
        prompt: "Giving OpenWebUI time to complete database migrations and internal setup"

    - name: 14. Check if LiteLLM is available (optional dependency)
      ansible.builtin.shell: |
        kubectl get svc litellm -n {{ ai_namespace }} -o jsonpath='{.metadata.name}'
      environment:
        KUBECONFIG: "{{ merged_kubeconf_file }}"
      register: litellm_check
      changed_when: false
      failed_when: false

    - name: 14.1. Display LiteLLM availability warning
      ansible.builtin.debug:
        msg: |
          ‚ö†Ô∏è LiteLLM service not found in namespace '{{ ai_namespace }}'.
          OpenWebUI is running but may have limited model access.

          To enable full model access, deploy LiteLLM first:
            uis deploy litellm

          Or OpenWebUI can connect directly to external Ollama via OLLAMA_API_BASE_URL.
      when: litellm_check.rc != 0

    - name: 15. Test OpenWebUI service connectivity from within cluster
      ansible.builtin.shell: |
        kubectl run curl-test --image=curlimages/curl --rm -i --restart=Never -n {{ ai_namespace }} -- \
        curl -s -w "HTTP_CODE:%{http_code}" http://open-webui:80/
      environment:
        KUBECONFIG: "{{ merged_kubeconf_file }}"
      register: openwebui_http_response
      retries: 15
      delay: 15
      until: openwebui_http_response.rc == 0 and openwebui_http_response.stdout.find('HTTP_CODE:200') != -1
      changed_when: false

    - name: 16. Display OpenWebUI connectivity test result on failure
      ansible.builtin.debug:
        msg:
          - "‚ùå OpenWebUI connectivity test failed!"
          - "Test output: {{ openwebui_http_response.stdout | default('No output') }}"
      when: openwebui_http_response.rc != 0 or openwebui_http_response.stdout.find('HTTP_CODE:200') == -1

    # Apply Open WebUI ingress configuration
    - name: 17. Apply Open WebUI ingress configuration
      ansible.builtin.command: >
        kubectl apply -f {{ openwebui_ingress_file }} -n {{ ai_namespace }}
      environment:
        KUBECONFIG: "{{ merged_kubeconf_file }}"
      register: openwebui_ingress_result
      changed_when: true
    
    - name: 18. Display Open WebUI ingress configuration result
      ansible.builtin.debug:
        msg: "Open WebUI ingress configuration applied"
    
    # Verify deployments and services
    - name: 19. Get all AI stack pods
      ansible.builtin.shell: |
        kubectl get pods -n {{ ai_namespace }}
      environment:
        KUBECONFIG: "{{ merged_kubeconf_file }}"
      register: ai_pods
      changed_when: false
    
    - name: 20. Display AI stack pods
      ansible.builtin.debug:
        var: ai_pods.stdout_lines
    
    - name: 21. Get all AI stack services
      ansible.builtin.shell: |
        kubectl get svc -n {{ ai_namespace }}
      environment:
        KUBECONFIG: "{{ merged_kubeconf_file }}"
      register: ai_services
      changed_when: false
    
    - name: 22. Display AI stack services
      ansible.builtin.debug:
        var: ai_services.stdout_lines
    
    # Get Open WebUI service name and port for access
    - name: 23. Get Open WebUI service details
      ansible.builtin.shell: |
        kubectl get svc -n {{ ai_namespace }} | grep open-webui | grep -v 'No resources'
      environment:
        KUBECONFIG: "{{ merged_kubeconf_file }}"
      register: openwebui_service
      changed_when: false
      ignore_errors: true
    
    - name: 24. Extract Open WebUI service name and port
      ansible.builtin.set_fact:
        openwebui_service_name: "{{ openwebui_service.stdout.split()[0] | default('open-webui') }}"
        openwebui_service_port: "{{ openwebui_service.stdout.split()[4].split(':')[0] | default('8080') }}"
      when: openwebui_service.stdout is defined and openwebui_service.stdout != ""
    
    # Determine if the installation was successful
    - name: 25. Count running pods
      ansible.builtin.shell: |
        kubectl get pods -n {{ ai_namespace }} | grep -v NAME | grep -c Running || echo "0"
      environment:
        KUBECONFIG: "{{ merged_kubeconf_file }}"
      register: running_pods_count
      changed_when: false
      ignore_errors: true
    
    - name: 26. Determine installation success
      ansible.builtin.set_fact:
        # Relaxed criteria - don't count on Ollama being ready
        services_setup_successful: "{{ (running_pods_count.stdout | int >= 3) }}"
    
    # FIX: Check for pods still initializing - modified to avoid shell arithmetic issues
    - name: 27. Check for pods still initializing
      ansible.builtin.shell: |
        CREATING_PODS=$(kubectl get pods -n {{ ai_namespace }} | grep -c "ContainerCreating" || echo "0")
        INIT_PODS=$(kubectl get pods -n {{ ai_namespace }} | grep -c "Init:" || echo "0")
        PENDING_PODS=$(kubectl get pods -n {{ ai_namespace }} | grep -c "Pending" || echo "0")
        TOTAL_INITIALIZING=$((${CREATING_PODS} + ${INIT_PODS} + ${PENDING_PODS}))
        echo "${TOTAL_INITIALIZING}"
      args:
        executable: /bin/bash
      environment:
        KUBECONFIG: "{{ merged_kubeconf_file }}"
      register: initializing_pods_count
      changed_when: false
      ignore_errors: true
    
    # FIX: Modified to avoid using ternary operator since it was causing issues
    - name: 28. Set initialization message
      ansible.builtin.set_fact:
        initialization_message: "Some pods are still initializing. This is normal for the first deployment."
      when: initializing_pods_count.stdout | int > 0
    
    - name: 29. Set initialization message when no pods initializing
      ansible.builtin.set_fact:
        initialization_message: "All pods have completed initialization."
      when: initializing_pods_count.stdout | int == 0
    
    - name: 30. Display final installation status
      ansible.builtin.debug:
        msg:
          - "==============================================="
          - "üöÄ Open WebUI AI Stack Installation Status"
          - "==============================================="
          - ""
          - "‚úÖ SUCCESS - All components verified and running"
          - ""
          - "üì¶ Components installed:"
          - "‚Ä¢ Persistent Storage"
          - "‚Ä¢ Apache Tika (document extraction)"
          - "‚Ä¢ LiteLLM (proxy for model access) - via separate deployment"
          - "‚Ä¢ Open WebUI (frontend connecting to LiteLLM proxy)"
          - "‚Ä¢ Note: In-cluster Ollama skipped (deploy_ollama_incluster=false)"
          - ""
          - "üîÑ Status:"
          - "‚Ä¢ Running pods: {{ running_pods_count.stdout }} / {{ ai_pods.stdout_lines | length - 1 }}"
          - "‚Ä¢ {{ initialization_message }}"
          - ""
          - "‚è≥ Note: Using LiteLLM proxy for model access."
          - "Models are served through LiteLLM from your Mac Ollama and cloud providers."
          - ""
          - "üöÄ Verification Results:"
          - "‚Ä¢ LiteLLM dependency: ‚úÖ Available"
          - "‚Ä¢ OpenWebUI HTTP: ‚úÖ Responding"
          - "‚Ä¢ Pod readiness: ‚úÖ All pods ready"
          - ""
          - "üåê Access Instructions:"
          - "1. Open WebUI:"
          - "   ‚Ä¢ Port-forward: kubectl port-forward svc/{{ openwebui_service_name | default('open-webui') }} {{ openwebui_service_port | default('8080') }}:{{ openwebui_service_port | default('8080') }} -n {{ ai_namespace }}"
          - "   ‚Ä¢ Access at: http://localhost:{{ openwebui_service_port | default('8080') }}"
          - "   ‚Ä¢ Or via ingress at: http://openwebui.localhost"
          - ""
          - "‚öôÔ∏è Model Management:"
          - "   ‚Ä¢ Models are accessed through LiteLLM proxy"
          - "   ‚Ä¢ Configure additional models in LiteLLM ConfigMap"
          - "   ‚Ä¢ Model access controlled via LiteLLM configuration"
          - ""
          - "üîß Troubleshooting:"
          - "‚Ä¢ Check pod status: kubectl get pods -n {{ ai_namespace }}"
          - "‚Ä¢ View OpenWebUI logs: kubectl logs -f statefulset/open-webui -n {{ ai_namespace }}"
          - "‚Ä¢ Check LiteLLM connection: kubectl logs -f deployment/litellm -n {{ ai_namespace }}"
          - "‚Ä¢ Restart OpenWebUI: kubectl rollout restart statefulset/open-webui -n {{ ai_namespace }}"
          - ""
          - "==============================================="
          - "{{ 'üéâ INSTALLATION SUCCESSFUL' if services_setup_successful else '‚ö†Ô∏è INSTALLATION STATUS: Some components may still be starting' }}"
          - "==============================================="